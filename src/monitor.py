import requests
import json
import os
from datetime import datetime, timezone
import cloudscraper
import time
import traceback
import random

class JewelryMonitor:
    def __init__(self):
        # ä½¿ç”¨ cloudscraper ä¾†ç¹é Cloudflare
        self.scraper = cloudscraper.create_scraper(
            browser={
                'browser': 'chrome',
                'platform': 'windows',
                'mobile': False
            }
        )
        
        # è¨­ç½®æ›´çœŸå¯¦çš„ headers
        self.scraper.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'zh-TW,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Sec-Fetch-Dest': 'empty',
            'Sec-Fetch-Mode': 'cors',
            'Sec-Fetch-Site': 'same-origin',
            'sec-ch-ua': '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
            'sec-ch-ua-mobile': '?0',
            'sec-ch-ua-platform': '"Windows"'
        })
        
        self.keywords = self.load_keywords()
        self.base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        self.results_dir = os.path.join(self.base_dir, "results")
        self.ensure_results_dir()
        
        # Telegram è¨­å®š
        self.telegram_token = os.environ.get('TELEGRAM_BOT_TOKEN')
        self.telegram_chat_id = os.environ.get('TELEGRAM_CHAT_ID')
        
        print(f"ğŸ”§ åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“ çµæœç›®éŒ„: {self.results_dir}")
        print(f"ğŸ“ é—œéµå­—æ•¸é‡: {len(self.keywords)}")
        
    def load_keywords(self):
        """è¼‰å…¥ç›£æ§é—œéµå­—"""
        return [
            # æ ¸å¿ƒé‡‘å·¥ç å¯¶é—œéµå­—
            "é‡‘å·¥", "éŠ€å·¥", "æ‰‹ä½œé‡‘å·¥", "é‡‘å·¥æ•™å­¸", "é‡‘å·¥èª²ç¨‹", "é‡‘å·¥å·¥ä½œå®¤",
            "ç å¯¶", "ç å¯¶è¨­è¨ˆ", "ç å¯¶è£½ä½œ", "é¦–é£¾", "é¦–é£¾è¨­è¨ˆ", "æ‰‹ä½œé¦–é£¾",
            
            # æŠ€è¡“å·¥è—
            "é‘²åµŒ", "å¯¶çŸ³é‘²åµŒ", "ç¶­ä¿®", "ç å¯¶ç¶­ä¿®", "é¦–é£¾ç¶­ä¿®", "æ”¹åœ",
            "æ‹‹å…‰", "é›»é", "ç„Šæ¥", "é›•è Ÿ", "é‘„é€ ",
            
            # ææ–™
            "Ké‡‘", "18K", "14K", "ç™½é‡‘", "é»ƒé‡‘", "ç«ç‘°é‡‘", "ç´”éŠ€", "925éŠ€",
            "é‘½çŸ³", "å¯¶çŸ³", "ç¿¡ç¿ ", "çç ", "ç´…å¯¶çŸ³", "è—å¯¶çŸ³", "ç¥–æ¯ç¶ ",
            
            # ç”¢å“
            "æˆ’æŒ‡", "é …éŠ", "æ‰‹éŠ", "è€³ç’°", "å©šæˆ’", "å°æˆ’", "æ±‚å©šæˆ’æŒ‡", "æƒ…ä¾¶æˆ’",
            
            # æœå‹™
            "è¨‚åš", "å®¢è£½", "è¨‚è£½", "æ¨è–¦", "åˆ†äº«", "è©•åƒ¹", "é–‹ç®±"
        ]
    
    def ensure_results_dir(self):
        """ç¢ºä¿çµæœç›®éŒ„å­˜åœ¨"""
        if not os.path.exists(self.results_dir):
            os.makedirs(self.results_dir)
            print(f"ğŸ“ å‰µå»ºçµæœç›®éŒ„: {self.results_dir}")
    
    def get_processed_posts(self):
        """ç²å–å·²è™•ç†çš„æ–‡ç« åˆ—è¡¨"""
        processed_file = os.path.join(self.results_dir, "processed_posts.txt")
        processed_posts = set()
        
        if os.path.exists(processed_file):
            with open(processed_file, 'r', encoding='utf-8') as f:
                processed_posts = set(line.strip() for line in f if line.strip())
        
        return processed_posts
    
    def save_processed_post(self, post_id):
        """è¨˜éŒ„å·²è™•ç†çš„æ–‡ç« """
        processed_file = os.path.join(self.results_dir, "processed_posts.txt")
        
        with open(processed_file, 'a', encoding='utf-8') as f:
            f.write(f"{post_id}\n")
    
    def get_dcard_posts(self, forum, limit=30):
        """ç²å– Dcard æ–‡ç«  - å¢å¼·ç‰ˆåçˆ¬èŸ²"""
        max_retries = 3
        
        for attempt in range(max_retries):
            try:
                print(f"ğŸ”„ å˜—è©¦ç¬¬ {attempt + 1} æ¬¡ç²å– {forum} ç‰ˆæ–‡ç« ...")
                
                # éš¨æ©Ÿå»¶é²é¿å…è¢«æª¢æ¸¬
                delay = random.uniform(2, 5)
                print(f"â³ ç­‰å¾… {delay:.1f} ç§’...")
                time.sleep(delay)
                
                # æ§‹å»º URL
                url = f"https://www.dcard.tw/service/api/v2/forums/{forum}/posts"
                params = {
                    'limit': limit,
                    'popular': 'false'  # ä½¿ç”¨å­—ä¸²è€Œä¸æ˜¯ Boolean
                }
                
                # æ›´æ–° Referer è®“è«‹æ±‚æ›´çœŸå¯¦
                self.scraper.headers.update({
                    'Referer': f'https://www.dcard.tw/f/{forum}',
                    'X-Requested-With': 'XMLHttpRequest'
                })
                
                print(f"ğŸ“¡ æ­£åœ¨è«‹æ±‚: {url}")
                response = self.scraper.get(
                    url, 
                    params=params, 
                    timeout=30,
                    allow_redirects=True
                )
                
                print(f"ğŸ“Š å›æ‡‰ç‹€æ…‹ç¢¼: {response.status_code}")
                
                if response.status_code == 200:
                    data = response.json()
                    print(f"âœ… æˆåŠŸç²å– {len(data)} ç¯‡æ–‡ç« ")
                    return data
                elif response.status_code == 403:
                    print(f"ğŸš« 403 éŒ¯èª¤ï¼Œç­‰å¾…æ›´é•·æ™‚é–“å¾Œé‡è©¦...")
                    time.sleep(10 + attempt * 5)
                else:
                    print(f"âš ï¸ æœªé æœŸçš„ç‹€æ…‹ç¢¼: {response.status_code}")
                    
            except requests.exceptions.RequestException as e:
                print(f"ğŸŒ ç¶²è·¯éŒ¯èª¤: {e}")
            except json.JSONDecodeError as e:
                print(f"ğŸ“„ JSON è§£æéŒ¯èª¤: {e}")
            except Exception as e:
                print(f"âŒ æœªçŸ¥éŒ¯èª¤: {e}")
                traceback.print_exc()
            
            if attempt < max_retries - 1:
                wait_time = (attempt + 1) * 10
                print(f"â³ ç­‰å¾… {wait_time} ç§’å¾Œé‡è©¦...")
                time.sleep(wait_time)
        
        print(f"âŒ ç²å– {forum} ç‰ˆæ–‡ç« å¤±æ•—ï¼Œå·²é‡è©¦ {max_retries} æ¬¡")
        return []
    
    def check_keywords(self, text):
        """æª¢æŸ¥é—œéµå­—åŒ¹é…"""
        if not text:
            return []
            
        text_lower = text.lower()
        matched = []
        
        for keyword in self.keywords:
            if keyword.lower() in text_lower:
                matched.append(keyword)
        
        return matched
    
    def save_match(self, post, forum, forum_name, keywords):
        """ä¿å­˜åŒ¹é…çµæœ"""
        now = datetime.now(timezone.utc)
        taiwan_time = now.replace(tzinfo=timezone.utc).astimezone(tz=None)
        
        url = f"https://www.dcard.tw/f/{forum}/p/{post['id']}"
        
        match_data = {
            'id': post['id'],
            'forum': forum,
            'forum_name': forum_name,
            'title': post.get('title', ''),
            'url': url,
            'author': f"{post.get('school', '')} {post.get('department', '')}".strip(),
            'matched_keywords': keywords,
            'excerpt': post.get('excerpt', '')[:200],
            'like_count': post.get('likeCount', 0),
            'comment_count': post.get('commentCount', 0),
            'created_at': post.get('createdAt', ''),
            'found_at': taiwan_time.strftime('%Y-%m-%d %H:%M:%S'),
            'found_at_utc': now.strftime('%Y-%m-%d %H:%M:%S UTC')
        }
        
        # ä¿å­˜åˆ° JSON æª”æ¡ˆ
        today = taiwan_time.strftime('%Y-%m-%d')
        json_file = os.path.join(self.results_dir, f"matches_{today}.json")
        
        matches = []
        if os.path.exists(json_file):
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    matches = json.load(f)
            except:
                matches = []
        
        matches.append(match_data)
        
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(matches, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜åˆ°ç¸½çµæœæª”æ¡ˆ
        summary_file = os.path.join(self.base_dir, "latest_matches.txt")
        with open(summary_file, 'a', encoding='utf-8') as f:
            f.write(f"\n{'='*60}\n")
            f.write(f"ç™¼ç¾æ™‚é–“: {match_data['found_at']} (å°ç£æ™‚é–“)\n")
            f.write(f"å¹³å°: Dcard {forum_name}\n")
            f.write(f"æ¨™é¡Œ: {match_data['title']}\n")
            f.write(f"ä½œè€…: {match_data['author']}\n")
            f.write(f"ç¶²å€: {url}\n")
            f.write(f"åŒ¹é…é—œéµå­—: {', '.join(keywords)}\n")
            f.write(f"æ„›å¿ƒ/ç•™è¨€: {match_data['like_count']}/{match_data['comment_count']}\n")
            f.write(f"æ‘˜è¦: {match_data['excerpt']}\n")
        
        print(f"âœ… ä¿å­˜åŒ¹é…: {post.get('title', '')[:50]}...")
        return match_data
    
    def send_telegram_notification(self, matches):
        """ç™¼é€ Telegram é€šçŸ¥"""
        if not self.telegram_token or not self.telegram_chat_id:
            print("âš ï¸ æœªè¨­å®š Telegramï¼Œè·³éé€šçŸ¥")
            return
            
        if not matches:
            return
        
        try:
            taiwan_time = datetime.now().strftime('%Y-%m-%d %H:%M')
            message = f"ğŸ¯ é‡‘å·¥ç å¯¶ç›£æ§å ±å‘Š ({taiwan_time})\n"
            message += f"ç™¼ç¾ {len(matches)} ç¯‡ç›¸é—œæ–‡ç« ï¼\n\n"
            
            for i, match in enumerate(matches[:3], 1):  # æœ€å¤šé¡¯ç¤º 3 ç¯‡
                message += f"{i}. {match['title'][:40]}...\n"
                message += f"   ğŸ“ {match['forum_name']}\n"
                message += f"   ğŸ”— {match['url']}\n"
                message += f"   ğŸ·ï¸ {', '.join(match['matched_keywords'][:3])}\n"
                message += f"   â¤ï¸ {match['like_count']} ğŸ’¬ {match['comment_count']}\n\n"
            
            if len(matches) > 3:
                message += f"... é‚„æœ‰ {len(matches) - 3} ç¯‡æ–‡ç« \n"
            
            message += "ğŸ“Š å®Œæ•´çµæœè«‹æŸ¥çœ‹ GitHub å„²å­˜åº«"
            
            url = f"https://api.telegram.org/bot{self.telegram_token}/sendMessage"
            data = {
                'chat_id': self.telegram_chat_id,
                'text': message,
                'disable_web_page_preview': True
            }
            
            response = requests.post(url, data=data, timeout=10)
            if response.status_code == 200:
                print("âœ… Telegram é€šçŸ¥ç™¼é€æˆåŠŸ")
            else:
                print(f"âŒ Telegram é€šçŸ¥ç™¼é€å¤±æ•—: {response.status_code}")
                
        except Exception as e:
            print(f"âŒ Telegram é€šçŸ¥éŒ¯èª¤: {e}")
    
    def monitor_forum(self, forum, forum_name):
        """ç›£æ§å–®å€‹è«–å£‡"""
        print(f"\nğŸ“± æ­£åœ¨æª¢æŸ¥ Dcard {forum_name}...")
        
        try:
            posts = self.get_dcard_posts(forum, limit=30)  # æ¸›å°‘è«‹æ±‚é‡
            
            if not posts:
                print(f"âš ï¸ {forum_name} æ²’æœ‰ç²å–åˆ°æ–‡ç« ï¼Œè·³éè™•ç†")
                return []
                
            processed_posts = self.get_processed_posts()
            matches = []
            
            print(f"ğŸ“„ ç²å–åˆ° {len(posts)} ç¯‡æ–‡ç« ï¼Œé–‹å§‹è™•ç†...")
            
            for post in posts:
                post_id = f"dcard_{forum}_{post['id']}"
                
                if post_id in processed_posts:
                    continue
                
                title = post.get('title', '')
                excerpt = post.get('excerpt', '')
                text = f"{title} {excerpt}"
                
                matched_keywords = self.check_keywords(text)
                
                if matched_keywords:
                    match_data = self.save_match(post, forum, forum_name, matched_keywords)
                    matches.append(match_data)
                
                self.save_processed_post(post_id)
                time.sleep(0.5)  # é¿å…è«‹æ±‚éå¿«
            
            print(f"âœ… {forum_name} å®Œæˆï¼Œç™¼ç¾ {len(matches)} ç¯‡åŒ¹é…")
            return matches
            
        except Exception as e:
            print(f"âŒ ç›£æ§ {forum_name} å¤±æ•—: {e}")
            traceback.print_exc()
            return []
    
    def generate_summary(self, all_matches):
        """ç”ŸæˆåŸ·è¡Œæ‘˜è¦"""
        taiwan_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        summary = {
            'execution_time': taiwan_time,
            'total_matches': len(all_matches),
            'matches_by_forum': {},
            'top_keywords': {},
            'matches': all_matches
        }
        
        # çµ±è¨ˆå„è«–å£‡
        for match in all_matches:
            forum = match['forum_name']
            summary['matches_by_forum'][forum] = summary['matches_by_forum'].get(forum, 0) + 1
        
        # çµ±è¨ˆé—œéµå­—
        for match in all_matches:
            for keyword in match['matched_keywords']:
                summary['top_keywords'][keyword] = summary['top_keywords'].get(keyword, 0) + 1
        
        # ä¿å­˜æ‘˜è¦
        summary_file = os.path.join(self.results_dir, "latest_summary.json")
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        # ä¹Ÿä¿å­˜åˆ°æ ¹ç›®éŒ„æ–¹ä¾¿æŸ¥çœ‹
        root_summary = os.path.join(self.base_dir, "monitoring_summary.json")
        with open(root_summary, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“Š æ‘˜è¦å·²ä¿å­˜: {summary_file}")
        return summary
    
    def run_monitoring(self):
        """åŸ·è¡Œç›£æ§ä»»å‹™"""
        start_time = datetime.now()
        print("ğŸš€ é–‹å§‹é‡‘å·¥ç å¯¶ç›£æ§ä»»å‹™")
        print(f"â° é–‹å§‹æ™‚é–“: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ¯ ç›£æ§é—œéµå­—: {len(self.keywords)} å€‹")
        
        forums = {
            'jewelry': 'ç å¯¶ç‰ˆ',
            'marriage': 'çµå©šç‰ˆ', 
            'girl': 'å¥³å­©ç‰ˆ'
        }
        
        all_matches = []
        
        for forum_key, forum_name in forums.items():
            try:
                matches = self.monitor_forum(forum_key, forum_name)
                all_matches.extend(matches)
                
                # è«–å£‡é–“è¼ƒé•·çš„é–“éš”
                wait_time = random.uniform(5, 10)
                print(f"â³ ç­‰å¾… {wait_time:.1f} ç§’å¾Œæª¢æŸ¥ä¸‹ä¸€å€‹è«–å£‡...")
                time.sleep(wait_time)
                
            except Exception as e:
                print(f"âŒ è™•ç† {forum_name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        
        # ç”Ÿæˆæ‘˜è¦å ±å‘Š
        summary = self.generate_summary(all_matches)
        
        # ç™¼é€é€šçŸ¥
        if all_matches:
            self.send_telegram_notification(all_matches)
        
        # è¼¸å‡ºçµæœ
        end_time = datetime.now()
        duration = (end_time - start_time).seconds
        
        print(f"\nğŸ‰ ç›£æ§ä»»å‹™å®Œæˆ!")
        print(f"â±ï¸ åŸ·è¡Œæ™‚é–“: {duration} ç§’")
        print(f"ğŸ“Š ç¸½è¨ˆç™¼ç¾: {len(all_matches)} ç¯‡åŒ¹é…æ–‡ç« ")
        
        if all_matches:
            print(f"ğŸ† å„è«–å£‡åŒ¹é…æ•¸:")
            for forum, count in summary['matches_by_forum'].items():
                print(f"   â€¢ {forum}: {count} ç¯‡")
        else:
            print("âœ… æœ¬æ¬¡æœªç™¼ç¾æ–°çš„åŒ¹é…æ–‡ç« ")

def main():
    try:
        monitor = JewelryMonitor()
        monitor.run_monitoring()
    except Exception as e:
        print(f"âŒ ç¨‹å¼åŸ·è¡Œå¤±æ•—: {e}")
        traceback.print_exc()
        exit(1)

if __name__ == "__main__":
    main()